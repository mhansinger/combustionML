{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import Callback\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def coeff_r2(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1257: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           1000        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "res1a_branch2a (Dense)           (None, 250)           62750       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 250)           0           res1a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 250)           0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res1a_branch2b (Dense)           (None, 250)           62750       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 250)           0           res1a_branch2b[0][0]             \n",
      "                                                                   dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 250)           0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 250)           0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res1b_branch2a (Dense)           (None, 250)           62750       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 250)           0           res1b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 250)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res1b_branch2b (Dense)           (None, 250)           62750       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 250)           0           res1b_branch2b[0][0]             \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 250)           0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 250)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res1c_branch2a (Dense)           (None, 250)           62750       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 250)           0           res1c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 250)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res1c_branch2b (Dense)           (None, 250)           62750       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 250)           0           res1c_branch2b[0][0]             \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 250)           0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 250)           0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 15)            3765        dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 381,265\n",
      "Trainable params: 381,265\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('3_Block_Nets/FPV_ANN_tabulated_Standard_250.H5')\n",
    "# model = load_model('../tmp/calc_100_3_3_cbrt.h5', custom_objects={'coeff_r2':coeff_r2})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "class data_scaler(object):\n",
    "    def __init__(self):\n",
    "        self.norm = None\n",
    "        self.norm_1 = None\n",
    "        self.std = None\n",
    "        self.case = None\n",
    "        self.scale = 1\n",
    "        self.bias = 1e-20\n",
    "#         self.bias = 1\n",
    "\n",
    "\n",
    "        self.switcher = {\n",
    "            'min_std': 'min_std',\n",
    "            'std2': 'std2',\n",
    "            'std_min':'std_min',\n",
    "            'min': 'min',\n",
    "            'no':'no',\n",
    "            'log': 'log',\n",
    "            'log_min':'log_min',\n",
    "            'log_std':'log_std',\n",
    "            'log2': 'log2',\n",
    "            'sqrt_std': 'sqrt_std',\n",
    "            'cbrt_std': 'cbrt_std',\n",
    "            'nrt_std':'nrt_std',\n",
    "            'tan': 'tan'\n",
    "        }\n",
    "\n",
    "    def fit_transform(self, input_data, case):\n",
    "        self.case = case\n",
    "        if self.switcher.get(self.case) == 'min_std':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.norm.fit_transform(input_data)\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "            out = self.norm.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            self.norm = MinMaxScaler()\n",
    "            out = self.norm.fit_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            self.norm = MinMaxScaler()\n",
    "            out = self.norm.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_std':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            self.norm = MinMaxScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.norm.fit_transform(input_data)\n",
    "            out = np.log(np.asarray(out) + self.bias)\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'sqrt_std':\n",
    "            out = np.sqrt(np.asarray(input_data / self.scale))\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'cbrt_std':\n",
    "            out = np.cbrt(np.asarray(input_data / self.scale))\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'nrt_std':\n",
    "            out = np.power(np.asarray(input_data / self.scale),1/4)\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            self.norm = MaxAbsScaler()\n",
    "            self.std = StandardScaler()\n",
    "            out = self.std.fit_transform(input_data)\n",
    "            out = self.norm.fit_transform(out)\n",
    "            out = np.tan(out / (2 * np.pi + self.bias))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def transform(self, input_data):\n",
    "        if self.switcher.get(self.case) == 'min_std':\n",
    "            out = self.norm.transform(input_data)\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            out = self.std.transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            out = self.std.transform(input_data)\n",
    "            out = self.norm.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            out = self.norm.transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            out = self.norm.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_std':\n",
    "            out = - np.log(np.asarray(input_data / self.scale) + self.bias)\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            out = self.norm.transform(input_data)\n",
    "            out = np.log(np.asarray(out) + self.bias)\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'sqrt_std':\n",
    "            out = np.sqrt(np.asarray(input_data / self.scale))\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'cbrt_std':\n",
    "            out = np.cbrt(np.asarray(input_data / self.scale))\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'nrt_std':\n",
    "            out = np.power(np.asarray(input_data / self.scale),1/4)\n",
    "            out = self.std.transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            out = self.std.transform(input_data)\n",
    "            out = self.norm.transform(out)\n",
    "            out = np.tan(out / (2 * np.pi + self.bias))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self, input_data):\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min_std':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = self.norm.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std2':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'std_min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "            out = self.std.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'no':\n",
    "            out = input_data\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_min':\n",
    "            out = self.norm.inverse_transform(input_data)\n",
    "            out = (np.exp(-out) - self.bias) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log_std':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = (np.exp(-out) - self.bias) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'log2':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = np.exp(out) - self.bias\n",
    "            out = self.norm.inverse_transform(out)\n",
    "\n",
    "        if self.switcher.get(self.case) == 'sqrt_std':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = np.power(out,2) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'cbrt_std':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = np.power(out,3) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'nrt_std':\n",
    "            out = self.std.inverse_transform(input_data)\n",
    "            out = np.power(out,4) * self.scale\n",
    "\n",
    "        if self.switcher.get(self.case) == 'tan':\n",
    "            out = (2 * np.pi + self.bias) * np.arctan(input_data)\n",
    "            out = self.norm.inverse_transform(out)\n",
    "            out = self.std.inverse_transform(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5_data(fileName, input_features, labels):\n",
    "    df = pd.read_hdf(fileName)\n",
    "#     df = df[df['f']<0.45]\n",
    "#     for i in range(5):\n",
    "#         pv_101=df[df['pv']==1]\n",
    "#         pv_101['pv']=pv_101['pv']+0.002*(i+1)\n",
    "#         df = pd.concat([df,pv_101])\n",
    "    \n",
    "    input_df=df[input_features]\n",
    "    in_scaler = data_scaler()\n",
    "    input_np = in_scaler.fit_transform(input_df.values,'std2')\n",
    "\n",
    "    label_df=df[labels].clip(0)\n",
    "#     if 'PVs' in labels:\n",
    "#       label_df['PVs']=np.log(label_df['PVs']+1)\n",
    "    out_scaler = data_scaler()\n",
    "    label_np = out_scaler.fit_transform(label_df.values,'cbrt_std')\n",
    "\n",
    "    return input_np, label_np, df, in_scaler, out_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H2', 'H', 'O', 'O2', 'OH', 'H2O', 'HO2', 'CH3', 'CH4', 'CO', 'CO2', 'CH2O', 'N2', 'T', 'PVs']\n"
     ]
    }
   ],
   "source": [
    "labels =  ['H2', 'H', 'O', 'O2', 'OH', 'H2O', 'HO2', 'CH3', 'CH4', 'CO', 'CO2', 'CH2O', 'N2', 'T', 'PVs']\n",
    "\n",
    "print(labels)\n",
    "\n",
    "input_features=['f','zeta','pv']\n",
    "\n",
    "# read in the data\n",
    "x_input, y_label, df, in_scaler, out_scaler = read_h5_data('data/tables_of_fgm.h5',input_features=input_features, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(8192, 3), b.shape=(3, 250), m=8192, n=250, k=3\n\t [[{{node dense_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_1_0_0/_263, dense_1/kernel/read)]]\n\t [[{{node dense_2/BiasAdd/_265}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_82_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-922e92209ea5>\", line 1, in <module>\n    model = load_model('3_Block_Nets/FPV_ANN_tabulated_Standard_250.H5')\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 240, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 304, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\", line 140, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 2416, in from_config\n    process_layer(layer_data)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 2411, in process_layer\n    layer(input_tensors[0], **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/core.py\", line 840, in call\n    output = K.dot(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 936, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2053, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8192, 3), b.shape=(3, 250), m=8192, n=250, k=3\n\t [[{{node dense_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_1_0_0/_263, dense_1/kernel/read)]]\n\t [[{{node dense_2/BiasAdd/_265}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_82_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(8192, 3), b.shape=(3, 250), m=8192, n=250, k=3\n\t [[{{node dense_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_1_0_0/_263, dense_1/kernel/read)]]\n\t [[{{node dense_2/BiasAdd/_265}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_82_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-22292ef5069c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredict_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpredict_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1585\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(8192, 3), b.shape=(3, 250), m=8192, n=250, k=3\n\t [[{{node dense_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_1_0_0/_263, dense_1/kernel/read)]]\n\t [[{{node dense_2/BiasAdd/_265}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_82_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'dense_1/MatMul', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-922e92209ea5>\", line 1, in <module>\n    model = load_model('3_Block_Nets/FPV_ANN_tabulated_Standard_250.H5')\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 240, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/models.py\", line 304, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\", line 140, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 2416, in from_config\n    process_layer(layer_data)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 2411, in process_layer\n    layer(input_tensors[0], **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/layers/core.py\", line 840, in call\n    output = K.dot(inputs, self.kernel)\n  File \"/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\", line 936, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2053, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(8192, 3), b.shape=(3, 250), m=8192, n=250, k=3\n\t [[{{node dense_1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_1_0_0/_263, dense_1/kernel/read)]]\n\t [[{{node dense_2/BiasAdd/_265}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_82_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_input,y_label, test_size=0.01)\n",
    "\n",
    "x_test_df = pd.DataFrame(in_scaler.inverse_transform(x_test),columns=input_features)\n",
    "y_test_df = pd.DataFrame(out_scaler.inverse_transform(y_test),columns=labels)\n",
    "\n",
    "\n",
    "predict_val = model.predict(x_test,batch_size=1024*8)\n",
    "predict_df = pd.DataFrame(out_scaler.inverse_transform(predict_val), columns=labels)\n",
    "\n",
    "df_test=pd.concat([x_test_df,y_test_df],axis=1)\n",
    "df_pred=pd.concat([x_test_df,predict_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considering the scaling for input, rescale zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-45f2e83c6db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzeta_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zeta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mzeta_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mzeta_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zeta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzeta_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "zeta_test=list(set(df_test['zeta']))\n",
    "zeta_test.sort()\n",
    "zeta_df=list(set(df['zeta']))\n",
    "zeta_df.sort()\n",
    "\n",
    "zeta_level = zeta_df\n",
    "\n",
    "df_pred.zeta=df_pred.zeta.replace(zeta_test,zeta_df)\n",
    "df_test.zeta=df_test.zeta.replace(zeta_test,zeta_df)\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r2 table for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_stats=pd.DataFrame()\n",
    "\n",
    "r2s=[]\n",
    "r2s_i=[]\n",
    "\n",
    "maxs_0=[]\n",
    "maxs_9=[]\n",
    "\n",
    "for r2,name in zip(r2_score(df_test,df_pred,multioutput='raw_values'),df_test.columns):\n",
    "  r2s.append(r2)\n",
    "    \n",
    "  maxs_0.append(df_test[df_test['zeta']==zeta_level[0]][name].max())\n",
    "  maxs_9.append(df_test[df_test['zeta']==zeta_level[9]][name].max())\n",
    "    \n",
    "  for i in zeta_level:\n",
    "    r2s_i.append(r2_score(df_pred[df_pred['zeta']==i][name],\n",
    "                          df_test[df_test['zeta']==i][name]))\n",
    "\n",
    "r2_stats['name']=df_test.columns\n",
    "r2_stats['z_scale']=[m_9/(m_0+1e-20) for m_9,m_0 in zip(maxs_9,maxs_0)]\n",
    "r2_stats['total r2 = ']=r2s\n",
    "\n",
    "tmp=np.asarray(r2s_i).reshape(-1,len(zeta_level))\n",
    "for idx,z in enumerate(zeta_level):\n",
    "  r2_stats['r2 = '+str(z)]=tmp[:,idx]\n",
    "\n",
    "# show all species \n",
    "df_dnn_r2=r2_stats.drop(columns=['z_scale'])[3:]\n",
    "df_dnn.to_csv('r2_table.csv')\n",
    "df_dnn_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r2 plots for all quantities in the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_show=df_test.sample(frac=0.05)\n",
    "df_pred_show=df_pred.iloc[df_test_show.index]\n",
    "\n",
    "for sp in labels:\n",
    "    x=df_test_show[sp]\n",
    "    y=df_pred_show[sp]\n",
    "    plt.scatter(x,y,c='r',s=1.5)\n",
    "    ax=plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.axis('off')\n",
    "    plt.savefig('scatter_plots/{0}_r2_ppor.eps'.format(sp),format='eps',bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "!mkdir figs\n",
    "!mv *.eps figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wireframe plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "def wireframe_plot(x,y,z,sp):\n",
    "    ax=plt.axes(projection='3d')\n",
    "    # make the panes transparent\n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    # make the grid lines transparent\n",
    "    # ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    # ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    # ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    #ax.set_axis_off()\n",
    "    ax.plot_wireframe(x,y,z)\n",
    "    plt.savefig('plots_3D/{0}_wireframe.eps'.format(sp),format='eps',bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "!rm *.eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots from original table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[df.zeta==0]['f'].values\n",
    "y=df[df.zeta==0]['pv'].values\n",
    "x=x.reshape(501,-1)\n",
    "y=y.reshape(501,-1)\n",
    "\n",
    "for sp in labels:\n",
    "    for zl in zeta_level:\n",
    "        z=df[df.zeta==zl][sp].values\n",
    "        z=z.reshape(501,-1)\n",
    "        wireframe_plot(x,y,z,'{0}_zeta_{1}_tab'.format(sp,zl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots form DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_val = model.predict(x_input,batch_size=1024*8)\n",
    "dnn_df = pd.DataFrame(out_scaler.inverse_transform(predict_val), columns=labels)\n",
    "\n",
    "df_dnn=pd.concat([df[input_features],dnn_df],axis=1)\n",
    "# df_dnn.head(5)\n",
    "\n",
    "for sp in labels:\n",
    "    for zl in zeta_level:\n",
    "        z=df_dnn[df_dnn.zeta==zl][sp].values\n",
    "        z=z.reshape(501,-1)\n",
    "        wireframe_plot(x,y,z,'{0}_zeta_{1}_dnn'.format(sp,zl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots of difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sp in labels:\n",
    "    for zl in zeta_level:\n",
    "        z=df_dnn[df_dnn.zeta==zl][sp].values - df[df.zeta==zl][sp].values\n",
    "        z=z.reshape(501,-1)\n",
    "        wireframe_plot(x,y,z,'{0}_zeta_{1}_diff'.format(sp,zl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv *.eps figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
